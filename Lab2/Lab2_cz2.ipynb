{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "95ca3330-70f4-4b7e-b325-00e819e4be63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##  **Zadanie 2**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d09f7ab-6da4-43f4-9660-c50a0c05c435",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>imdb_title_id</th><th>weighted_average_vote</th><th>total_votes</th><th>mean_vote</th><th>median_vote</th><th>votes_10</th><th>votes_9</th><th>votes_8</th><th>votes_7</th><th>votes_6</th><th>votes_5</th><th>votes_4</th><th>votes_3</th><th>votes_2</th><th>votes_1</th><th>allgenders_0age_avg_vote</th><th>allgenders_0age_votes</th><th>allgenders_18age_avg_vote</th><th>allgenders_18age_votes</th><th>allgenders_30age_avg_vote</th><th>allgenders_30age_votes</th><th>allgenders_45age_avg_vote</th><th>allgenders_45age_votes</th><th>males_allages_avg_vote</th><th>males_allages_votes</th><th>males_0age_avg_vote</th><th>males_0age_votes</th><th>males_18age_avg_vote</th><th>males_18age_votes</th><th>males_30age_avg_vote</th><th>males_30age_votes</th><th>males_45age_avg_vote</th><th>males_45age_votes</th><th>females_allages_avg_vote</th><th>females_allages_votes</th><th>females_0age_avg_vote</th><th>females_0age_votes</th><th>females_18age_avg_vote</th><th>females_18age_votes</th><th>females_30age_avg_vote</th><th>females_30age_votes</th><th>females_45age_avg_vote</th><th>females_45age_votes</th><th>top1000_voters_rating</th><th>top1000_voters_votes</th><th>us_voters_rating</th><th>us_voters_votes</th><th>non_us_voters_rating</th><th>non_us_voters_votes</th></tr></thead><tbody><tr><td>tt0000009</td><td>5.9</td><td>154</td><td>5.9</td><td>6.0</td><td>12</td><td>4</td><td>10</td><td>43</td><td>28</td><td>28</td><td>9</td><td>1</td><td>5</td><td>14</td><td>7.2</td><td>4.0</td><td>6.0</td><td>38.0</td><td>5.7</td><td>50.0</td><td>6.6</td><td>35.0</td><td>6.2</td><td>97.0</td><td>7.0</td><td>1.0</td><td>5.9</td><td>24.0</td><td>5.6</td><td>36.0</td><td>6.7</td><td>31.0</td><td>6.0</td><td>35.0</td><td>7.3</td><td>3.0</td><td>5.9</td><td>14.0</td><td>5.7</td><td>13.0</td><td>4.5</td><td>4.0</td><td>5.7</td><td>34.0</td><td>6.4</td><td>51.0</td><td>6.0</td><td>70.0</td></tr><tr><td>tt0000574</td><td>6.1</td><td>589</td><td>6.3</td><td>6.0</td><td>57</td><td>18</td><td>58</td><td>137</td><td>139</td><td>103</td><td>28</td><td>20</td><td>13</td><td>16</td><td>6.0</td><td>1.0</td><td>6.1</td><td>114.0</td><td>6.0</td><td>239.0</td><td>6.3</td><td>115.0</td><td>6.1</td><td>425.0</td><td>6.0</td><td>1.0</td><td>6.2</td><td>102.0</td><td>6.0</td><td>210.0</td><td>6.2</td><td>100.0</td><td>6.2</td><td>50.0</td><td>null</td><td>null</td><td>5.9</td><td>12.0</td><td>6.2</td><td>23.0</td><td>6.6</td><td>14.0</td><td>6.4</td><td>66.0</td><td>6.0</td><td>96.0</td><td>6.2</td><td>331.0</td></tr><tr><td>tt0001892</td><td>5.8</td><td>188</td><td>6.0</td><td>6.0</td><td>6</td><td>6</td><td>17</td><td>44</td><td>52</td><td>32</td><td>16</td><td>5</td><td>6</td><td>4</td><td>null</td><td>null</td><td>5.5</td><td>25.0</td><td>5.8</td><td>72.0</td><td>6.2</td><td>62.0</td><td>5.9</td><td>146.0</td><td>null</td><td>null</td><td>5.5</td><td>21.0</td><td>5.9</td><td>67.0</td><td>6.2</td><td>55.0</td><td>5.7</td><td>15.0</td><td>null</td><td>null</td><td>5.8</td><td>4.0</td><td>5.8</td><td>4.0</td><td>6.8</td><td>7.0</td><td>5.4</td><td>32.0</td><td>6.2</td><td>31.0</td><td>5.9</td><td>123.0</td></tr><tr><td>tt0002101</td><td>5.2</td><td>446</td><td>5.3</td><td>5.0</td><td>15</td><td>8</td><td>16</td><td>62</td><td>98</td><td>117</td><td>63</td><td>26</td><td>25</td><td>16</td><td>null</td><td>null</td><td>5.3</td><td>23.0</td><td>5.0</td><td>111.0</td><td>5.3</td><td>193.0</td><td>5.1</td><td>299.0</td><td>null</td><td>null</td><td>5.2</td><td>20.0</td><td>4.9</td><td>96.0</td><td>5.2</td><td>171.0</td><td>5.9</td><td>39.0</td><td>null</td><td>null</td><td>5.7</td><td>3.0</td><td>5.5</td><td>14.0</td><td>6.1</td><td>21.0</td><td>4.9</td><td>57.0</td><td>5.5</td><td>207.0</td><td>4.7</td><td>105.0</td></tr><tr><td>tt0002130</td><td>7.0</td><td>2237</td><td>6.9</td><td>7.0</td><td>210</td><td>225</td><td>436</td><td>641</td><td>344</td><td>169</td><td>66</td><td>39</td><td>20</td><td>87</td><td>7.5</td><td>4.0</td><td>7.0</td><td>402.0</td><td>7.0</td><td>895.0</td><td>7.1</td><td>482.0</td><td>7.0</td><td>1607.0</td><td>8.0</td><td>2.0</td><td>7.0</td><td>346.0</td><td>7.0</td><td>804.0</td><td>7.0</td><td>396.0</td><td>7.2</td><td>215.0</td><td>7.0</td><td>2.0</td><td>7.0</td><td>52.0</td><td>7.3</td><td>82.0</td><td>7.4</td><td>77.0</td><td>6.9</td><td>139.0</td><td>7.0</td><td>488.0</td><td>7.0</td><td>1166.0</td></tr><tr><td>tt0002199</td><td>5.7</td><td>484</td><td>5.8</td><td>6.0</td><td>33</td><td>15</td><td>48</td><td>80</td><td>123</td><td>77</td><td>36</td><td>20</td><td>18</td><td>34</td><td>null</td><td>null</td><td>5.6</td><td>35.0</td><td>5.6</td><td>177.0</td><td>5.8</td><td>168.0</td><td>5.7</td><td>354.0</td><td>null</td><td>null</td><td>5.6</td><td>32.0</td><td>5.7</td><td>159.0</td><td>5.8</td><td>151.0</td><td>5.8</td><td>31.0</td><td>null</td><td>null</td><td>6.3</td><td>3.0</td><td>5.1</td><td>13.0</td><td>6.5</td><td>15.0</td><td>5.5</td><td>67.0</td><td>5.9</td><td>173.0</td><td>5.6</td><td>181.0</td></tr><tr><td>tt0002423</td><td>6.8</td><td>753</td><td>6.8</td><td>7.0</td><td>80</td><td>65</td><td>105</td><td>209</td><td>142</td><td>80</td><td>27</td><td>13</td><td>4</td><td>28</td><td>3.0</td><td>1.0</td><td>6.4</td><td>59.0</td><td>6.7</td><td>287.0</td><td>7.0</td><td>276.0</td><td>6.6</td><td>530.0</td><td>3.0</td><td>1.0</td><td>6.4</td><td>41.0</td><td>6.6</td><td>240.0</td><td>6.8</td><td>238.0</td><td>7.4</td><td>93.0</td><td>null</td><td>null</td><td>6.5</td><td>16.0</td><td>7.2</td><td>40.0</td><td>8.2</td><td>34.0</td><td>6.2</td><td>88.0</td><td>6.6</td><td>139.0</td><td>6.8</td><td>455.0</td></tr><tr><td>tt0002445</td><td>6.2</td><td>273</td><td>6.2</td><td>6.0</td><td>15</td><td>8</td><td>30</td><td>74</td><td>66</td><td>40</td><td>22</td><td>6</td><td>2</td><td>10</td><td>6.0</td><td>1.0</td><td>5.9</td><td>34.0</td><td>6.2</td><td>99.0</td><td>6.3</td><td>69.0</td><td>6.2</td><td>191.0</td><td>6.0</td><td>1.0</td><td>5.8</td><td>29.0</td><td>6.2</td><td>85.0</td><td>6.3</td><td>64.0</td><td>6.3</td><td>21.0</td><td>null</td><td>null</td><td>6.5</td><td>5.0</td><td>6.3</td><td>11.0</td><td>6.2</td><td>5.0</td><td>5.7</td><td>41.0</td><td>5.8</td><td>40.0</td><td>6.2</td><td>154.0</td></tr><tr><td>tt0002452</td><td>6.7</td><td>198</td><td>7.1</td><td>7.0</td><td>53</td><td>7</td><td>23</td><td>35</td><td>30</td><td>24</td><td>12</td><td>5</td><td>3</td><td>6</td><td>null</td><td>null</td><td>7.4</td><td>28.0</td><td>6.7</td><td>104.0</td><td>6.5</td><td>39.0</td><td>6.7</td><td>153.0</td><td>null</td><td>null</td><td>7.3</td><td>24.0</td><td>6.6</td><td>92.0</td><td>6.5</td><td>33.0</td><td>7.0</td><td>19.0</td><td>null</td><td>null</td><td>8.3</td><td>3.0</td><td>6.8</td><td>10.0</td><td>6.8</td><td>6.0</td><td>5.4</td><td>25.0</td><td>6.7</td><td>25.0</td><td>6.8</td><td>135.0</td></tr><tr><td>tt0002461</td><td>5.5</td><td>225</td><td>5.4</td><td>6.0</td><td>9</td><td>6</td><td>22</td><td>34</td><td>53</td><td>40</td><td>23</td><td>8</td><td>4</td><td>26</td><td>null</td><td>null</td><td>5.9</td><td>11.0</td><td>5.3</td><td>95.0</td><td>5.8</td><td>72.0</td><td>5.5</td><td>168.0</td><td>null</td><td>null</td><td>5.9</td><td>11.0</td><td>5.2</td><td>88.0</td><td>5.8</td><td>63.0</td><td>7.7</td><td>15.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>7.2</td><td>6.0</td><td>9.7</td><td>9.0</td><td>5.4</td><td>37.0</td><td>5.8</td><td>109.0</td><td>5.4</td><td>68.0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "tt0000009",
         5.9,
         154,
         5.9,
         6.0,
         12,
         4,
         10,
         43,
         28,
         28,
         9,
         1,
         5,
         14,
         7.2,
         4.0,
         6.0,
         38.0,
         5.7,
         50.0,
         6.6,
         35.0,
         6.2,
         97.0,
         7.0,
         1.0,
         5.9,
         24.0,
         5.6,
         36.0,
         6.7,
         31.0,
         6.0,
         35.0,
         7.3,
         3.0,
         5.9,
         14.0,
         5.7,
         13.0,
         4.5,
         4.0,
         5.7,
         34.0,
         6.4,
         51.0,
         6.0,
         70.0
        ],
        [
         "tt0000574",
         6.1,
         589,
         6.3,
         6.0,
         57,
         18,
         58,
         137,
         139,
         103,
         28,
         20,
         13,
         16,
         6.0,
         1.0,
         6.1,
         114.0,
         6.0,
         239.0,
         6.3,
         115.0,
         6.1,
         425.0,
         6.0,
         1.0,
         6.2,
         102.0,
         6.0,
         210.0,
         6.2,
         100.0,
         6.2,
         50.0,
         null,
         null,
         5.9,
         12.0,
         6.2,
         23.0,
         6.6,
         14.0,
         6.4,
         66.0,
         6.0,
         96.0,
         6.2,
         331.0
        ],
        [
         "tt0001892",
         5.8,
         188,
         6.0,
         6.0,
         6,
         6,
         17,
         44,
         52,
         32,
         16,
         5,
         6,
         4,
         null,
         null,
         5.5,
         25.0,
         5.8,
         72.0,
         6.2,
         62.0,
         5.9,
         146.0,
         null,
         null,
         5.5,
         21.0,
         5.9,
         67.0,
         6.2,
         55.0,
         5.7,
         15.0,
         null,
         null,
         5.8,
         4.0,
         5.8,
         4.0,
         6.8,
         7.0,
         5.4,
         32.0,
         6.2,
         31.0,
         5.9,
         123.0
        ],
        [
         "tt0002101",
         5.2,
         446,
         5.3,
         5.0,
         15,
         8,
         16,
         62,
         98,
         117,
         63,
         26,
         25,
         16,
         null,
         null,
         5.3,
         23.0,
         5.0,
         111.0,
         5.3,
         193.0,
         5.1,
         299.0,
         null,
         null,
         5.2,
         20.0,
         4.9,
         96.0,
         5.2,
         171.0,
         5.9,
         39.0,
         null,
         null,
         5.7,
         3.0,
         5.5,
         14.0,
         6.1,
         21.0,
         4.9,
         57.0,
         5.5,
         207.0,
         4.7,
         105.0
        ],
        [
         "tt0002130",
         7.0,
         2237,
         6.9,
         7.0,
         210,
         225,
         436,
         641,
         344,
         169,
         66,
         39,
         20,
         87,
         7.5,
         4.0,
         7.0,
         402.0,
         7.0,
         895.0,
         7.1,
         482.0,
         7.0,
         1607.0,
         8.0,
         2.0,
         7.0,
         346.0,
         7.0,
         804.0,
         7.0,
         396.0,
         7.2,
         215.0,
         7.0,
         2.0,
         7.0,
         52.0,
         7.3,
         82.0,
         7.4,
         77.0,
         6.9,
         139.0,
         7.0,
         488.0,
         7.0,
         1166.0
        ],
        [
         "tt0002199",
         5.7,
         484,
         5.8,
         6.0,
         33,
         15,
         48,
         80,
         123,
         77,
         36,
         20,
         18,
         34,
         null,
         null,
         5.6,
         35.0,
         5.6,
         177.0,
         5.8,
         168.0,
         5.7,
         354.0,
         null,
         null,
         5.6,
         32.0,
         5.7,
         159.0,
         5.8,
         151.0,
         5.8,
         31.0,
         null,
         null,
         6.3,
         3.0,
         5.1,
         13.0,
         6.5,
         15.0,
         5.5,
         67.0,
         5.9,
         173.0,
         5.6,
         181.0
        ],
        [
         "tt0002423",
         6.8,
         753,
         6.8,
         7.0,
         80,
         65,
         105,
         209,
         142,
         80,
         27,
         13,
         4,
         28,
         3.0,
         1.0,
         6.4,
         59.0,
         6.7,
         287.0,
         7.0,
         276.0,
         6.6,
         530.0,
         3.0,
         1.0,
         6.4,
         41.0,
         6.6,
         240.0,
         6.8,
         238.0,
         7.4,
         93.0,
         null,
         null,
         6.5,
         16.0,
         7.2,
         40.0,
         8.2,
         34.0,
         6.2,
         88.0,
         6.6,
         139.0,
         6.8,
         455.0
        ],
        [
         "tt0002445",
         6.2,
         273,
         6.2,
         6.0,
         15,
         8,
         30,
         74,
         66,
         40,
         22,
         6,
         2,
         10,
         6.0,
         1.0,
         5.9,
         34.0,
         6.2,
         99.0,
         6.3,
         69.0,
         6.2,
         191.0,
         6.0,
         1.0,
         5.8,
         29.0,
         6.2,
         85.0,
         6.3,
         64.0,
         6.3,
         21.0,
         null,
         null,
         6.5,
         5.0,
         6.3,
         11.0,
         6.2,
         5.0,
         5.7,
         41.0,
         5.8,
         40.0,
         6.2,
         154.0
        ],
        [
         "tt0002452",
         6.7,
         198,
         7.1,
         7.0,
         53,
         7,
         23,
         35,
         30,
         24,
         12,
         5,
         3,
         6,
         null,
         null,
         7.4,
         28.0,
         6.7,
         104.0,
         6.5,
         39.0,
         6.7,
         153.0,
         null,
         null,
         7.3,
         24.0,
         6.6,
         92.0,
         6.5,
         33.0,
         7.0,
         19.0,
         null,
         null,
         8.3,
         3.0,
         6.8,
         10.0,
         6.8,
         6.0,
         5.4,
         25.0,
         6.7,
         25.0,
         6.8,
         135.0
        ],
        [
         "tt0002461",
         5.5,
         225,
         5.4,
         6.0,
         9,
         6,
         22,
         34,
         53,
         40,
         23,
         8,
         4,
         26,
         null,
         null,
         5.9,
         11.0,
         5.3,
         95.0,
         5.8,
         72.0,
         5.5,
         168.0,
         null,
         null,
         5.9,
         11.0,
         5.2,
         88.0,
         5.8,
         63.0,
         7.7,
         15.0,
         null,
         null,
         null,
         null,
         7.2,
         6.0,
         9.7,
         9.0,
         5.4,
         37.0,
         5.8,
         109.0,
         5.4,
         68.0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "imdb_title_id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "weighted_average_vote",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "total_votes",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "mean_vote",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "median_vote",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "votes_10",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "votes_9",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "votes_8",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "votes_7",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "votes_6",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "votes_5",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "votes_4",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "votes_3",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "votes_2",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "votes_1",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "allgenders_0age_avg_vote",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "allgenders_0age_votes",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "allgenders_18age_avg_vote",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "allgenders_18age_votes",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "allgenders_30age_avg_vote",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "allgenders_30age_votes",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "allgenders_45age_avg_vote",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "allgenders_45age_votes",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "males_allages_avg_vote",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "males_allages_votes",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "males_0age_avg_vote",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "males_0age_votes",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "males_18age_avg_vote",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "males_18age_votes",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "males_30age_avg_vote",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "males_30age_votes",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "males_45age_avg_vote",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "males_45age_votes",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "females_allages_avg_vote",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "females_allages_votes",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "females_0age_avg_vote",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "females_0age_votes",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "females_18age_avg_vote",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "females_18age_votes",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "females_30age_avg_vote",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "females_30age_votes",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "females_45age_avg_vote",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "females_45age_votes",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "top1000_voters_rating",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "top1000_voters_votes",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "us_voters_rating",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "us_voters_votes",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "non_us_voters_rating",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "non_us_voters_votes",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = \"dbfs:/FileStore/tables/Files/ratings.csv\"\n",
    "ratings_df = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "        .option(\"inferSchema\",\"true\") \\\n",
    "            .load(path)\n",
    "display(ratings_df.limit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12d18e9f-220c-44ec-8222-418a927642cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import * \n",
    "ratings_schema=StructType([StructField(\"imdb_title_id\", StringType(), True), # True/False -- czy moze byc komorka z NULL\n",
    "                    StructField(\"weighted_average_vote\", DoubleType(), True),\n",
    "                    StructField(\"total_votes\", IntegerType(), True),\n",
    "                    StructField(\"mean_vote\", DoubleType(), True),\n",
    "                    StructField(\"median_vote\", DoubleType(),True)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12a61fe4-3ace-409e-a05b-ca11096c07aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>imdb_title_id</th><th>weighted_average_vote</th><th>total_votes</th><th>mean_vote</th><th>median_vote</th></tr></thead><tbody><tr><td>tt0000009</td><td>5.9</td><td>154</td><td>5.9</td><td>6.0</td></tr><tr><td>tt0000574</td><td>6.1</td><td>589</td><td>6.3</td><td>6.0</td></tr><tr><td>tt0001892</td><td>5.8</td><td>188</td><td>6.0</td><td>6.0</td></tr><tr><td>tt0002101</td><td>5.2</td><td>446</td><td>5.3</td><td>5.0</td></tr><tr><td>tt0002130</td><td>7.0</td><td>2237</td><td>6.9</td><td>7.0</td></tr><tr><td>tt0002199</td><td>5.7</td><td>484</td><td>5.8</td><td>6.0</td></tr><tr><td>tt0002423</td><td>6.8</td><td>753</td><td>6.8</td><td>7.0</td></tr><tr><td>tt0002445</td><td>6.2</td><td>273</td><td>6.2</td><td>6.0</td></tr><tr><td>tt0002452</td><td>6.7</td><td>198</td><td>7.1</td><td>7.0</td></tr><tr><td>tt0002461</td><td>5.5</td><td>225</td><td>5.4</td><td>6.0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "tt0000009",
         5.9,
         154,
         5.9,
         6.0
        ],
        [
         "tt0000574",
         6.1,
         589,
         6.3,
         6.0
        ],
        [
         "tt0001892",
         5.8,
         188,
         6.0,
         6.0
        ],
        [
         "tt0002101",
         5.2,
         446,
         5.3,
         5.0
        ],
        [
         "tt0002130",
         7.0,
         2237,
         6.9,
         7.0
        ],
        [
         "tt0002199",
         5.7,
         484,
         5.8,
         6.0
        ],
        [
         "tt0002423",
         6.8,
         753,
         6.8,
         7.0
        ],
        [
         "tt0002445",
         6.2,
         273,
         6.2,
         6.0
        ],
        [
         "tt0002452",
         6.7,
         198,
         7.1,
         7.0
        ],
        [
         "tt0002461",
         5.5,
         225,
         5.4,
         6.0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "imdb_title_id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "weighted_average_vote",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "total_votes",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "mean_vote",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "median_vote",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>imdb_title_id</th><th>weighted_average_vote</th><th>total_votes</th><th>mean_vote</th><th>median_vote</th></tr></thead><tbody><tr><td>tt0000009</td><td>5.9</td><td>154</td><td>5.9</td><td>6.0</td></tr><tr><td>tt0000574</td><td>6.1</td><td>589</td><td>6.3</td><td>6.0</td></tr><tr><td>tt0001892</td><td>5.8</td><td>188</td><td>6.0</td><td>6.0</td></tr><tr><td>tt0002101</td><td>5.2</td><td>446</td><td>5.3</td><td>5.0</td></tr><tr><td>tt0002130</td><td>7.0</td><td>higher then 1000</td><td>6.9</td><td>7.0</td></tr><tr><td>tt0002199</td><td>5.7</td><td>484</td><td>5.8</td><td>6.0</td></tr><tr><td>tt0002423</td><td>6.8</td><td>753</td><td>6.8</td><td>7.0</td></tr><tr><td>tt0002445</td><td>6.2</td><td>273</td><td>6.2</td><td>6.0</td></tr><tr><td>tt0002452</td><td>6.7</td><td>198</td><td>7.1</td><td>7.0</td></tr><tr><td>tt0002461</td><td>5.5</td><td>225</td><td>5.4</td><td>6.0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "tt0000009",
         5.9,
         "154",
         5.9,
         6.0
        ],
        [
         "tt0000574",
         6.1,
         "589",
         6.3,
         6.0
        ],
        [
         "tt0001892",
         5.8,
         "188",
         6.0,
         6.0
        ],
        [
         "tt0002101",
         5.2,
         "446",
         5.3,
         5.0
        ],
        [
         "tt0002130",
         7.0,
         "higher then 1000",
         6.9,
         7.0
        ],
        [
         "tt0002199",
         5.7,
         "484",
         5.8,
         6.0
        ],
        [
         "tt0002423",
         6.8,
         "753",
         6.8,
         7.0
        ],
        [
         "tt0002445",
         6.2,
         "273",
         6.2,
         6.0
        ],
        [
         "tt0002452",
         6.7,
         "198",
         7.1,
         7.0
        ],
        [
         "tt0002461",
         5.5,
         "225",
         5.4,
         6.0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "imdb_title_id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "weighted_average_vote",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "total_votes",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "mean_vote",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "median_vote",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import when, col\n",
    "schema = spark.read.format(\"csv\").option(\"header\",\"true\").schema(ratings_schema).load(path)\n",
    "display(schema.limit(10))\n",
    "schema2 = schema.withColumn(\"total_votes\", when(col(\"total_votes\") > 1000 , \"higher then 1000\").otherwise(col(\"total_votes\")))\n",
    "display(schema2.limit(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a9650805-5775-4466-90ee-2f25b9d9a161",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## **Zadanie** 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54d2fe49-d4b0-43a3-8f3d-2a78b2228937",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read Modes\n",
    "\n",
    "#PERMISSIVE: Jeśli atrybuty nie mogą zostać wczytane Spark zamienia je na nule\n",
    "#DROPMALFORMED: wiersze są usuwane\n",
    "#FAILFAST: proces odczytu zostaje całkowicie zatrzymany\n",
    "#Bad Records Path: lokalizacja storage gdzie błędne dane zostaną zapisane \n",
    "ratings_Permissive = spark.read.format('csv') \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "        .schema(ratings_schema) \\\n",
    "            .option(\"mode\", \"PERMISSIVE\") \\\n",
    "                .load(path)\n",
    "\n",
    "ratings_Failfast = spark.read.format('csv') \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "        .schema(ratings_schema) \\\n",
    "            .option(\"mode\", \"FAILFAST\") \\\n",
    "                .load(path)\n",
    "\n",
    "ratings_Dropmalformed = spark.read.format('csv') \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "        .schema(ratings_schema) \\\n",
    "            .option(\"mode\", \"DROPMALFORMED\") \\\n",
    "                .load(path)\n",
    "ratings_BadRecords = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "        .schema(ratings_schema) \\\n",
    "            .option(\"badRecordsPath\", \"/mnt/source/badrecords\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4044f304-d455-4f80-accc-014738a3b3c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>imdb_title_id</th><th>weighted_average_vote</th><th>total_votes</th><th>mean_vote</th><th>median_vote</th></tr></thead><tbody><tr><td>tt0000009</td><td>5.9</td><td>154</td><td>5.9</td><td>6.0</td></tr><tr><td>tt0000574</td><td>null</td><td>589</td><td>6.3</td><td>6.0</td></tr><tr><td>tt0001892</td><td>5.8</td><td>188</td><td>6.0</td><td>6.0</td></tr><tr><td>tt0002101</td><td>5.2</td><td>446</td><td>5.3</td><td>5.0</td></tr><tr><td>tt0002130</td><td>null</td><td>2237</td><td>6.9</td><td>7.0</td></tr><tr><td>tt0002199</td><td>5.7</td><td>484</td><td>5.8</td><td>6.0</td></tr><tr><td>tt0002423</td><td>null</td><td>753</td><td>6.8</td><td>7.0</td></tr><tr><td>tt0002445</td><td>null</td><td>273</td><td>6.2</td><td>6.0</td></tr><tr><td>tt0002452</td><td>null</td><td>198</td><td>7.1</td><td>7.0</td></tr><tr><td>tt0002461</td><td>5.5</td><td>225</td><td>5.4</td><td>6.0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "tt0000009",
         "5.9",
         154,
         5.9,
         6.0
        ],
        [
         "tt0000574",
         "null",
         589,
         6.3,
         6.0
        ],
        [
         "tt0001892",
         "5.8",
         188,
         6.0,
         6.0
        ],
        [
         "tt0002101",
         "5.2",
         446,
         5.3,
         5.0
        ],
        [
         "tt0002130",
         "null",
         2237,
         6.9,
         7.0
        ],
        [
         "tt0002199",
         "5.7",
         484,
         5.8,
         6.0
        ],
        [
         "tt0002423",
         "null",
         753,
         6.8,
         7.0
        ],
        [
         "tt0002445",
         "null",
         273,
         6.2,
         6.0
        ],
        [
         "tt0002452",
         "null",
         198,
         7.1,
         7.0
        ],
        [
         "tt0002461",
         "5.5",
         225,
         5.4,
         6.0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "imdb_title_id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "weighted_average_vote",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "total_votes",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "mean_vote",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "median_vote",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>imdb_title_id</th><th>weighted_average_vote</th><th>total_votes</th><th>mean_vote</th><th>median_vote</th></tr></thead><tbody><tr><td>tt0000009</td><td>5.9</td><td>154</td><td>5.9</td><td>6.0</td></tr><tr><td>tt0000574</td><td>null</td><td>589</td><td>6.3</td><td>6.0</td></tr><tr><td>tt0001892</td><td>5.8</td><td>188</td><td>6.0</td><td>6.0</td></tr><tr><td>tt0002101</td><td>5.2</td><td>446</td><td>5.3</td><td>5.0</td></tr><tr><td>tt0002130</td><td>null</td><td>2237</td><td>6.9</td><td>7.0</td></tr><tr><td>tt0002199</td><td>5.7</td><td>484</td><td>5.8</td><td>6.0</td></tr><tr><td>tt0002423</td><td>null</td><td>753</td><td>6.8</td><td>7.0</td></tr><tr><td>tt0002445</td><td>null</td><td>273</td><td>6.2</td><td>6.0</td></tr><tr><td>tt0002452</td><td>null</td><td>198</td><td>7.1</td><td>7.0</td></tr><tr><td>tt0002461</td><td>5.5</td><td>225</td><td>5.4</td><td>6.0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "tt0000009",
         5.9,
         154,
         5.9,
         6.0
        ],
        [
         "tt0000574",
         null,
         589,
         6.3,
         6.0
        ],
        [
         "tt0001892",
         5.8,
         188,
         6.0,
         6.0
        ],
        [
         "tt0002101",
         5.2,
         446,
         5.3,
         5.0
        ],
        [
         "tt0002130",
         null,
         2237,
         6.9,
         7.0
        ],
        [
         "tt0002199",
         5.7,
         484,
         5.8,
         6.0
        ],
        [
         "tt0002423",
         null,
         753,
         6.8,
         7.0
        ],
        [
         "tt0002445",
         null,
         273,
         6.2,
         6.0
        ],
        [
         "tt0002452",
         null,
         198,
         7.1,
         7.0
        ],
        [
         "tt0002461",
         5.5,
         225,
         5.4,
         6.0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "imdb_title_id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "weighted_average_vote",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "total_votes",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "mean_vote",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "median_vote",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql.functions import *\n",
    "ratings_Permissive = ratings_Permissive.withColumn(\"weighted_average_vote\", when(col(\"weighted_average_vote\") > 6, 'null').otherwise(col(\"weighted_average_vote\")))\n",
    "ratings_Permissive.write.mode(\"overwrite\").csv(\"dbfs:/tmp/broken.csv\", header=True)\n",
    "display(ratings_Permissive.limit(10))\n",
    "### Permissive\n",
    "ratings_broken_Permissive = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "        .schema(ratings_schema) \\\n",
    "            .option(\"mode\", \"PERMISSIVE\") \\\n",
    "                .load(\"dbfs:/tmp/broken.csv\")\n",
    "display(ratings_broken_Permissive.limit(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08db8fe4-2fb9-47c3-8a99-3b00ddcf419e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 24.0 failed 1 times, most recent failure: Lost task 0.0 in stage 24.0 (TID 56) (ip-10-172-255-103.us-west-2.compute.internal executor driver): com.databricks.sql.io.FileReadException: Error while reading file dbfs:/tmp/broken.csv/part-00000-tid-5336668563910744420-ff19a290-498e-4769-9c4f-bfa3c75e1ad7-48-1-c000.csv.\n",
       "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1$$anon$2.logFileNameAndThrow(FileScanRDD.scala:704)\n",
       "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1$$anon$2.getNext(FileScanRDD.scala:673)\n",
       "\tat org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:73)\n",
       "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.$anonfun$hasNext$1(FileScanRDD.scala:493)\n",
       "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
       "\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n",
       "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:486)\n",
       "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
       "\tat org.apache.spark.sql.execution.collect.UnsafeRowBatchUtils$.encodeUnsafeRows(UnsafeRowBatchUtils.scala:82)\n",
       "\tat org.apache.spark.sql.execution.collect.Collector.$anonfun$processFunc$1(Collector.scala:208)\n",
       "\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$3(ResultTask.scala:75)\n",
       "\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n",
       "\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$1(ResultTask.scala:75)\n",
       "\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n",
       "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:55)\n",
       "\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:179)\n",
       "\tat org.apache.spark.scheduler.Task.$anonfun$run$5(Task.scala:142)\n",
       "\tat com.databricks.unity.EmptyHandle$.runWithAndClose(UCSHandle.scala:126)\n",
       "\tat org.apache.spark.scheduler.Task.$anonfun$run$1(Task.scala:142)\n",
       "\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n",
       "\tat org.apache.spark.scheduler.Task.run(Task.scala:97)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$13(Executor.scala:904)\n",
       "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1741)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:907)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:761)\n",
       "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
       "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
       "\tat java.lang.Thread.run(Thread.java:750)\n",
       "Caused by: org.apache.spark.SparkException: Malformed records are detected in record parsing. Parse Mode: FAILFAST. To process malformed records as null result, try setting the option 'mode' as 'PERMISSIVE'.\n",
       "\tat org.apache.spark.sql.errors.QueryExecutionErrors$.malformedRecordsDetectedInRecordParsingError(QueryExecutionErrors.scala:1936)\n",
       "\tat org.apache.spark.sql.catalyst.util.FailureSafeParser.parse(FailureSafeParser.scala:103)\n",
       "\tat org.apache.spark.sql.catalyst.csv.UnivocityParser$.$anonfun$parseIterator$2(UnivocityParser.scala:507)\n",
       "\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n",
       "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n",
       "\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n",
       "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
       "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1$$anon$2.getNext(FileScanRDD.scala:619)\n",
       "\t... 28 more\n",
       "Caused by: org.apache.spark.sql.catalyst.util.BadRecordException: java.lang.NumberFormatException: For input string: \"null\"\n",
       "Caused by: java.lang.NumberFormatException: For input string: \"null\"\n",
       "\tat sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:2043)\n",
       "\tat sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110)\n",
       "\tat java.lang.Double.parseDouble(Double.java:538)\n",
       "\tat scala.collection.immutable.StringLike.toDouble(StringLike.scala:321)\n",
       "\tat scala.collection.immutable.StringLike.toDouble$(StringLike.scala:321)\n",
       "\tat scala.collection.immutable.StringOps.toDouble(StringOps.scala:33)\n",
       "\tat org.apache.spark.sql.catalyst.csv.UnivocityParser.$anonfun$makeConverter$12(UnivocityParser.scala:220)\n",
       "\tat org.apache.spark.sql.catalyst.csv.UnivocityParser.nullSafeDatum(UnivocityParser.scala:305)\n",
       "\tat org.apache.spark.sql.catalyst.csv.UnivocityParser.$anonfun$makeConverter$11(UnivocityParser.scala:216)\n",
       "\tat org.apache.spark.sql.catalyst.csv.UnivocityParser.convert(UnivocityParser.scala:360)\n",
       "\tat org.apache.spark.sql.catalyst.csv.UnivocityParser.$anonfun$parse$2(UnivocityParser.scala:321)\n",
       "\tat org.apache.spark.sql.catalyst.csv.UnivocityParser$.$anonfun$parseIterator$1(UnivocityParser.scala:499)\n",
       "\tat org.apache.spark.sql.catalyst.util.FailureSafeParser.parse(FailureSafeParser.scala:92)\n",
       "\tat org.apache.spark.sql.catalyst.csv.UnivocityParser$.$anonfun$parseIterator$2(UnivocityParser.scala:507)\n",
       "\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n",
       "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n",
       "\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n",
       "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
       "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1$$anon$2.getNext(FileScanRDD.scala:619)\n",
       "\tat org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:73)\n",
       "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.$anonfun$hasNext$1(FileScanRDD.scala:493)\n",
       "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
       "\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n",
       "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:486)\n",
       "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
       "\tat org.apache.spark.sql.execution.collect.UnsafeRowBatchUtils$.encodeUnsafeRows(UnsafeRowBatchUtils.scala:82)\n",
       "\tat org.apache.spark.sql.execution.collect.Collector.$anonfun$processFunc$1(Collector.scala:208)\n",
       "\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$3(ResultTask.scala:75)\n",
       "\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n",
       "\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$1(ResultTask.scala:75)\n",
       "\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n",
       "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:55)\n",
       "\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:179)\n",
       "\tat org.apache.spark.scheduler.Task.$anonfun$run$5(Task.scala:142)\n",
       "\tat com.databricks.unity.EmptyHandle$.runWithAndClose(UCSHandle.scala:126)\n",
       "\tat org.apache.spark.scheduler.Task.$anonfun$run$1(Task.scala:142)\n",
       "\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n",
       "\tat org.apache.spark.scheduler.Task.run(Task.scala:97)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$13(Executor.scala:904)\n",
       "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1741)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:907)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:761)\n",
       "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
       "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
       "\tat java.lang.Thread.run(Thread.java:750)\n",
       "\n",
       "Driver stacktrace:\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:3440)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:3362)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:3351)\n",
       "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
       "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
       "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:3351)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1460)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1460)\n",
       "\tat scala.Option.foreach(Option.scala:407)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1460)\n",
       "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3651)\n",
       "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3589)\n",
       "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3577)\n",
       "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:51)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$runJob$1(DAGScheduler.scala:1209)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1197)\n",
       "\tat org.apache.spark.SparkContext.runJobInternal(SparkContext.scala:2758)\n",
       "\tat org.apache.spark.sql.execution.collect.Collector.$anonfun$runSparkJobs$1(Collector.scala:349)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\n",
       "\tat org.apache.spark.sql.execution.collect.Collector.runSparkJobs(Collector.scala:293)\n",
       "\tat org.apache.spark.sql.execution.collect.Collector.collect(Collector.scala:377)\n",
       "\tat org.apache.spark.sql.execution.collect.Collector$.collect(Collector.scala:128)\n",
       "\tat org.apache.spark.sql.execution.collect.Collector$.collect(Collector.scala:135)\n",
       "\tat org.apache.spark.sql.execution.qrc.InternalRowFormat$.collect(cachedSparkResults.scala:122)\n",
       "\tat org.apache.spark.sql.execution.qrc.InternalRowFormat$.collect(cachedSparkResults.scala:110)\n",
       "\tat org.apache.spark.sql.execution.qrc.InternalRowFormat$.collect(cachedSparkResults.scala:92)\n",
       "\tat org.apache.spark.sql.execution.qrc.ResultCacheManager.$anonfun$computeResult$1(ResultCacheManager.scala:537)\n",
       "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\n",
       "\tat org.apache.spark.sql.execution.qrc.ResultCacheManager.collectResult$1(ResultCacheManager.scala:529)\n",
       "\tat org.apache.spark.sql.execution.qrc.ResultCacheManager.computeResult(ResultCacheManager.scala:549)\n",
       "\tat org.apache.spark.sql.execution.qrc.ResultCacheManager.$anonfun$getOrComputeResultInternal$1(ResultCacheManager.scala:402)\n",
       "\tat scala.Option.getOrElse(Option.scala:189)\n",
       "\tat org.apache.spark.sql.execution.qrc.ResultCacheManager.getOrComputeResultInternal(ResultCacheManager.scala:395)\n",
       "\tat org.apache.spark.sql.execution.qrc.ResultCacheManager.getOrComputeResult(ResultCacheManager.scala:289)\n",
       "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeCollectResult$1(SparkPlan.scala:506)\n",
       "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\n",
       "\tat org.apache.spark.sql.execution.SparkPlan.executeCollectResult(SparkPlan.scala:503)\n",
       "\tat org.apache.spark.sql.Dataset.collectResult(Dataset.scala:3458)\n",
       "\tat org.apache.spark.sql.Dataset.$anonfun$collectResult$1(Dataset.scala:3449)\n",
       "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$3(Dataset.scala:4373)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:841)\n",
       "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4371)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$9(SQLExecution.scala:258)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:448)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:203)\n",
       "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1073)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:131)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:398)\n",
       "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:4371)\n",
       "\tat org.apache.spark.sql.Dataset.collectResult(Dataset.scala:3448)\n",
       "\tat com.databricks.backend.daemon.driver.OutputAggregator$.withOutputAggregation0(OutputAggregator.scala:267)\n",
       "\tat com.databricks.backend.daemon.driver.OutputAggregator$.withOutputAggregation(OutputAggregator.scala:101)\n",
       "\tat com.databricks.backend.daemon.driver.PythonDriverLocalBase.generateTableResult(PythonDriverLocalBase.scala:727)\n",
       "\tat com.databricks.backend.daemon.driver.JupyterDriverLocal.computeListResultsItem(JupyterDriverLocal.scala:887)\n",
       "\tat com.databricks.backend.daemon.driver.JupyterDriverLocal$JupyterEntryPoint.addCustomDisplayData(JupyterDriverLocal.scala:286)\n",
       "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
       "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
       "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
       "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
       "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
       "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n",
       "\tat py4j.Gateway.invoke(Gateway.java:306)\n",
       "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
       "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
       "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:195)\n",
       "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:115)\n",
       "\tat java.lang.Thread.run(Thread.java:750)\n",
       "Caused by: com.databricks.sql.io.FileReadException: Error while reading file dbfs:/tmp/broken.csv/part-00000-tid-5336668563910744420-ff19a290-498e-4769-9c4f-bfa3c75e1ad7-48-1-c000.csv.\n",
       "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1$$anon$2.logFileNameAndThrow(FileScanRDD.scala:704)\n",
       "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1$$anon$2.getNext(FileScanRDD.scala:673)\n",
       "\tat org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:73)\n",
       "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.$anonfun$hasNext$1(FileScanRDD.scala:493)\n",
       "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
       "\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n",
       "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:486)\n",
       "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
       "\tat org.apache.spark.sql.execution.collect.UnsafeRowBatchUtils$.encodeUnsafeRows(UnsafeRowBatchUtils.scala:82)\n",
       "\tat org.apache.spark.sql.execution.collect.Collector.$anonfun$processFunc$1(Collector.scala:208)\n",
       "\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$3(ResultTask.scala:75)\n",
       "\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n",
       "\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$1(ResultTask.scala:75)\n",
       "\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n",
       "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:55)\n",
       "\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:179)\n",
       "\tat org.apache.spark.scheduler.Task.$anonfun$run$5(Task.scala:142)\n",
       "\tat com.databricks.unity.EmptyHandle$.runWithAndClose(UCSHandle.scala:126)\n",
       "\tat org.apache.spark.scheduler.Task.$anonfun$run$1(Task.scala:142)\n",
       "\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n",
       "\tat org.apache.spark.scheduler.Task.run(Task.scala:97)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$13(Executor.scala:904)\n",
       "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1741)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:907)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:761)\n",
       "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
       "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
       "\t... 1 more\n",
       "Caused by: org.apache.spark.SparkException: Malformed records are detected in record parsing. Parse Mode: FAILFAST. To process malformed records as null result, try setting the option 'mode' as 'PERMISSIVE'.\n",
       "\tat org.apache.spark.sql.errors.QueryExecutionErrors$.malformedRecordsDetectedInRecordParsingError(QueryExecutionErrors.scala:1936)\n",
       "\tat org.apache.spark.sql.catalyst.util.FailureSafeParser.parse(FailureSafeParser.scala:103)\n",
       "\tat org.apache.spark.sql.catalyst.csv.UnivocityParser$.$anonfun$parseIterator$2(UnivocityParser.scala:507)\n",
       "\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n",
       "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n",
       "\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n",
       "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
       "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1$$anon$2.getNext(FileScanRDD.scala:619)\n",
       "\t... 28 more\n",
       "Caused by: org.apache.spark.sql.catalyst.util.BadRecordException: java.lang.NumberFormatException: For input string: \"null\"\n",
       "Caused by: java.lang.NumberFormatException: For input string: \"null\"\n",
       "\tat sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:2043)\n",
       "\tat sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110)\n",
       "\tat java.lang.Double.parseDouble(Double.java:538)\n",
       "\tat scala.collection.immutable.StringLike.toDouble(StringLike.scala:321)\n",
       "\tat scala.collection.immutable.StringLike.toDouble$(StringLike.scala:321)\n",
       "\tat scala.collection.immutable.StringOps.toDouble(StringOps.scala:33)\n",
       "\tat org.apache.spark.sql.catalyst.csv.UnivocityParser.$anonfun$makeConverter$12(UnivocityParser.scala:220)\n",
       "\tat org.apache.spark.sql.catalyst.csv.UnivocityParser.nullSafeDatum(UnivocityParser.scala:305)\n",
       "\tat org.apache.spark.sql.catalyst.csv.UnivocityParser.$anonfun$makeConverter$11(UnivocityParser.scala:216)\n",
       "\tat org.apache.spark.sql.catalyst.csv.UnivocityParser.convert(UnivocityParser.scala:360)\n",
       "\tat org.apache.spark.sql.catalyst.csv.UnivocityParser.$anonfun$parse$2(UnivocityParser.scala:321)\n",
       "\tat org.apache.spark.sql.catalyst.csv.UnivocityParser$.$anonfun$parseIterator$1(UnivocityParser.scala:499)\n",
       "\tat org.apache.spark.sql.catalyst.util.FailureSafeParser.parse(FailureSafeParser.scala:92)\n",
       "\tat org.apache.spark.sql.catalyst.csv.UnivocityParser$.$anonfun$parseIterator$2(UnivocityParser.scala:507)\n",
       "\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n",
       "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n",
       "\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n",
       "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
       "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1$$anon$2.getNext(FileScanRDD.scala:619)\n",
       "\tat org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:73)\n",
       "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.$anonfun$hasNext$1(FileScanRDD.scala:493)\n",
       "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
       "\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n",
       "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:486)\n",
       "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
       "\tat org.apache.spark.sql.execution.collect.UnsafeRowBatchUtils$.encodeUnsafeRows(UnsafeRowBatchUtils.scala:82)\n",
       "\tat org.apache.spark.sql.execution.collect.Collector.$anonfun$processFunc$1(Collector.scala:208)\n",
       "\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$3(ResultTask.scala:75)\n",
       "\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n",
       "\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$1(ResultTask.scala:75)\n",
       "\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n",
       "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:55)\n",
       "\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:179)\n",
       "\tat org.apache.spark.scheduler.Task.$anonfun$run$5(Task.scala:142)\n",
       "\tat com.databricks.unity.EmptyHandle$.runWithAndClose(UCSHandle.scala:126)\n",
       "\tat org.apache.spark.scheduler.Task.$anonfun$run$1(Task.scala:142)\n",
       "\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n",
       "\tat org.apache.spark.scheduler.Task.run(Task.scala:97)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$13(Executor.scala:904)\n",
       "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1741)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:907)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:761)\n",
       "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
       "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
       "\tat java.lang.Thread.run(Thread.java:750)"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 24.0 failed 1 times, most recent failure: Lost task 0.0 in stage 24.0 (TID 56) (ip-10-172-255-103.us-west-2.compute.internal executor driver): com.databricks.sql.io.FileReadException: Error while reading file dbfs:/tmp/broken.csv/part-00000-tid-5336668563910744420-ff19a290-498e-4769-9c4f-bfa3c75e1ad7-48-1-c000.csv.\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1$$anon$2.logFileNameAndThrow(FileScanRDD.scala:704)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1$$anon$2.getNext(FileScanRDD.scala:673)\n\tat org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:73)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.$anonfun$hasNext$1(FileScanRDD.scala:493)\n\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:486)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.execution.collect.UnsafeRowBatchUtils$.encodeUnsafeRows(UnsafeRowBatchUtils.scala:82)\n\tat org.apache.spark.sql.execution.collect.Collector.$anonfun$processFunc$1(Collector.scala:208)\n\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$3(ResultTask.scala:75)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$1(ResultTask.scala:75)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:55)\n\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:179)\n\tat org.apache.spark.scheduler.Task.$anonfun$run$5(Task.scala:142)\n\tat com.databricks.unity.EmptyHandle$.runWithAndClose(UCSHandle.scala:126)\n\tat org.apache.spark.scheduler.Task.$anonfun$run$1(Task.scala:142)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:97)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$13(Executor.scala:904)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1741)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:907)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:761)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Malformed records are detected in record parsing. Parse Mode: FAILFAST. To process malformed records as null result, try setting the option 'mode' as 'PERMISSIVE'.\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.malformedRecordsDetectedInRecordParsingError(QueryExecutionErrors.scala:1936)\n\tat org.apache.spark.sql.catalyst.util.FailureSafeParser.parse(FailureSafeParser.scala:103)\n\tat org.apache.spark.sql.catalyst.csv.UnivocityParser$.$anonfun$parseIterator$2(UnivocityParser.scala:507)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1$$anon$2.getNext(FileScanRDD.scala:619)\n\t... 28 more\nCaused by: org.apache.spark.sql.catalyst.util.BadRecordException: java.lang.NumberFormatException: For input string: \"null\"\nCaused by: java.lang.NumberFormatException: For input string: \"null\"\n\tat sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:2043)\n\tat sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110)\n\tat java.lang.Double.parseDouble(Double.java:538)\n\tat scala.collection.immutable.StringLike.toDouble(StringLike.scala:321)\n\tat scala.collection.immutable.StringLike.toDouble$(StringLike.scala:321)\n\tat scala.collection.immutable.StringOps.toDouble(StringOps.scala:33)\n\tat org.apache.spark.sql.catalyst.csv.UnivocityParser.$anonfun$makeConverter$12(UnivocityParser.scala:220)\n\tat org.apache.spark.sql.catalyst.csv.UnivocityParser.nullSafeDatum(UnivocityParser.scala:305)\n\tat org.apache.spark.sql.catalyst.csv.UnivocityParser.$anonfun$makeConverter$11(UnivocityParser.scala:216)\n\tat org.apache.spark.sql.catalyst.csv.UnivocityParser.convert(UnivocityParser.scala:360)\n\tat org.apache.spark.sql.catalyst.csv.UnivocityParser.$anonfun$parse$2(UnivocityParser.scala:321)\n\tat org.apache.spark.sql.catalyst.csv.UnivocityParser$.$anonfun$parseIterator$1(UnivocityParser.scala:499)\n\tat org.apache.spark.sql.catalyst.util.FailureSafeParser.parse(FailureSafeParser.scala:92)\n\tat org.apache.spark.sql.catalyst.csv.UnivocityParser$.$anonfun$parseIterator$2(UnivocityParser.scala:507)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1$$anon$2.getNext(FileScanRDD.scala:619)\n\tat org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:73)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.$anonfun$hasNext$1(FileScanRDD.scala:493)\n\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:486)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.execution.collect.UnsafeRowBatchUtils$.encodeUnsafeRows(UnsafeRowBatchUtils.scala:82)\n\tat org.apache.spark.sql.execution.collect.Collector.$anonfun$processFunc$1(Collector.scala:208)\n\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$3(ResultTask.scala:75)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$1(ResultTask.scala:75)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:55)\n\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:179)\n\tat org.apache.spark.scheduler.Task.$anonfun$run$5(Task.scala:142)\n\tat com.databricks.unity.EmptyHandle$.runWithAndClose(UCSHandle.scala:126)\n\tat org.apache.spark.scheduler.Task.$anonfun$run$1(Task.scala:142)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:97)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$13(Executor.scala:904)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1741)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:907)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:761)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:3440)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:3362)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:3351)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:3351)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1460)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1460)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1460)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3651)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3589)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3577)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:51)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$runJob$1(DAGScheduler.scala:1209)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1197)\n\tat org.apache.spark.SparkContext.runJobInternal(SparkContext.scala:2758)\n\tat org.apache.spark.sql.execution.collect.Collector.$anonfun$runSparkJobs$1(Collector.scala:349)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\n\tat org.apache.spark.sql.execution.collect.Collector.runSparkJobs(Collector.scala:293)\n\tat org.apache.spark.sql.execution.collect.Collector.collect(Collector.scala:377)\n\tat org.apache.spark.sql.execution.collect.Collector$.collect(Collector.scala:128)\n\tat org.apache.spark.sql.execution.collect.Collector$.collect(Collector.scala:135)\n\tat org.apache.spark.sql.execution.qrc.InternalRowFormat$.collect(cachedSparkResults.scala:122)\n\tat org.apache.spark.sql.execution.qrc.InternalRowFormat$.collect(cachedSparkResults.scala:110)\n\tat org.apache.spark.sql.execution.qrc.InternalRowFormat$.collect(cachedSparkResults.scala:92)\n\tat org.apache.spark.sql.execution.qrc.ResultCacheManager.$anonfun$computeResult$1(ResultCacheManager.scala:537)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\n\tat org.apache.spark.sql.execution.qrc.ResultCacheManager.collectResult$1(ResultCacheManager.scala:529)\n\tat org.apache.spark.sql.execution.qrc.ResultCacheManager.computeResult(ResultCacheManager.scala:549)\n\tat org.apache.spark.sql.execution.qrc.ResultCacheManager.$anonfun$getOrComputeResultInternal$1(ResultCacheManager.scala:402)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat org.apache.spark.sql.execution.qrc.ResultCacheManager.getOrComputeResultInternal(ResultCacheManager.scala:395)\n\tat org.apache.spark.sql.execution.qrc.ResultCacheManager.getOrComputeResult(ResultCacheManager.scala:289)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeCollectResult$1(SparkPlan.scala:506)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollectResult(SparkPlan.scala:503)\n\tat org.apache.spark.sql.Dataset.collectResult(Dataset.scala:3458)\n\tat org.apache.spark.sql.Dataset.$anonfun$collectResult$1(Dataset.scala:3449)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$3(Dataset.scala:4373)\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:841)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4371)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$9(SQLExecution.scala:258)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:448)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:203)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1073)\n\tat org.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:131)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:398)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:4371)\n\tat org.apache.spark.sql.Dataset.collectResult(Dataset.scala:3448)\n\tat com.databricks.backend.daemon.driver.OutputAggregator$.withOutputAggregation0(OutputAggregator.scala:267)\n\tat com.databricks.backend.daemon.driver.OutputAggregator$.withOutputAggregation(OutputAggregator.scala:101)\n\tat com.databricks.backend.daemon.driver.PythonDriverLocalBase.generateTableResult(PythonDriverLocalBase.scala:727)\n\tat com.databricks.backend.daemon.driver.JupyterDriverLocal.computeListResultsItem(JupyterDriverLocal.scala:887)\n\tat com.databricks.backend.daemon.driver.JupyterDriverLocal$JupyterEntryPoint.addCustomDisplayData(JupyterDriverLocal.scala:286)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:306)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:195)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:115)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: com.databricks.sql.io.FileReadException: Error while reading file dbfs:/tmp/broken.csv/part-00000-tid-5336668563910744420-ff19a290-498e-4769-9c4f-bfa3c75e1ad7-48-1-c000.csv.\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1$$anon$2.logFileNameAndThrow(FileScanRDD.scala:704)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1$$anon$2.getNext(FileScanRDD.scala:673)\n\tat org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:73)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.$anonfun$hasNext$1(FileScanRDD.scala:493)\n\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:486)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.execution.collect.UnsafeRowBatchUtils$.encodeUnsafeRows(UnsafeRowBatchUtils.scala:82)\n\tat org.apache.spark.sql.execution.collect.Collector.$anonfun$processFunc$1(Collector.scala:208)\n\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$3(ResultTask.scala:75)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$1(ResultTask.scala:75)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:55)\n\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:179)\n\tat org.apache.spark.scheduler.Task.$anonfun$run$5(Task.scala:142)\n\tat com.databricks.unity.EmptyHandle$.runWithAndClose(UCSHandle.scala:126)\n\tat org.apache.spark.scheduler.Task.$anonfun$run$1(Task.scala:142)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:97)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$13(Executor.scala:904)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1741)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:907)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:761)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\nCaused by: org.apache.spark.SparkException: Malformed records are detected in record parsing. Parse Mode: FAILFAST. To process malformed records as null result, try setting the option 'mode' as 'PERMISSIVE'.\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.malformedRecordsDetectedInRecordParsingError(QueryExecutionErrors.scala:1936)\n\tat org.apache.spark.sql.catalyst.util.FailureSafeParser.parse(FailureSafeParser.scala:103)\n\tat org.apache.spark.sql.catalyst.csv.UnivocityParser$.$anonfun$parseIterator$2(UnivocityParser.scala:507)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1$$anon$2.getNext(FileScanRDD.scala:619)\n\t... 28 more\nCaused by: org.apache.spark.sql.catalyst.util.BadRecordException: java.lang.NumberFormatException: For input string: \"null\"\nCaused by: java.lang.NumberFormatException: For input string: \"null\"\n\tat sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:2043)\n\tat sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110)\n\tat java.lang.Double.parseDouble(Double.java:538)\n\tat scala.collection.immutable.StringLike.toDouble(StringLike.scala:321)\n\tat scala.collection.immutable.StringLike.toDouble$(StringLike.scala:321)\n\tat scala.collection.immutable.StringOps.toDouble(StringOps.scala:33)\n\tat org.apache.spark.sql.catalyst.csv.UnivocityParser.$anonfun$makeConverter$12(UnivocityParser.scala:220)\n\tat org.apache.spark.sql.catalyst.csv.UnivocityParser.nullSafeDatum(UnivocityParser.scala:305)\n\tat org.apache.spark.sql.catalyst.csv.UnivocityParser.$anonfun$makeConverter$11(UnivocityParser.scala:216)\n\tat org.apache.spark.sql.catalyst.csv.UnivocityParser.convert(UnivocityParser.scala:360)\n\tat org.apache.spark.sql.catalyst.csv.UnivocityParser.$anonfun$parse$2(UnivocityParser.scala:321)\n\tat org.apache.spark.sql.catalyst.csv.UnivocityParser$.$anonfun$parseIterator$1(UnivocityParser.scala:499)\n\tat org.apache.spark.sql.catalyst.util.FailureSafeParser.parse(FailureSafeParser.scala:92)\n\tat org.apache.spark.sql.catalyst.csv.UnivocityParser$.$anonfun$parseIterator$2(UnivocityParser.scala:507)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1$$anon$2.getNext(FileScanRDD.scala:619)\n\tat org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:73)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.$anonfun$hasNext$1(FileScanRDD.scala:493)\n\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:486)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.execution.collect.UnsafeRowBatchUtils$.encodeUnsafeRows(UnsafeRowBatchUtils.scala:82)\n\tat org.apache.spark.sql.execution.collect.Collector.$anonfun$processFunc$1(Collector.scala:208)\n\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$3(ResultTask.scala:75)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$1(ResultTask.scala:75)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:55)\n\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:179)\n\tat org.apache.spark.scheduler.Task.$anonfun$run$5(Task.scala:142)\n\tat com.databricks.unity.EmptyHandle$.runWithAndClose(UCSHandle.scala:126)\n\tat org.apache.spark.scheduler.Task.$anonfun$run$1(Task.scala:142)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:97)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$13(Executor.scala:904)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1741)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:907)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:761)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\n",
       "errorSummary": "FileReadException: Error while reading file dbfs:/tmp/broken.csv/part-00000-tid-5336668563910744420-ff19a290-498e-4769-9c4f-bfa3c75e1ad7-48-1-c000.csv.\nCaused by: SparkException: Malformed records are detected in record parsing. Parse Mode: FAILFAST. To process malformed records as null result, try setting the option 'mode' as 'PERMISSIVE'.\nCaused by: BadRecordException: java.lang.NumberFormatException: For input string: \"null\"\nCaused by: NumberFormatException: For input string: \"null\"",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Failfast\n",
    "ratings_broken_Failfast = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "        .schema(ratings_schema) \\\n",
    "            .option(\"mode\", \"FAILFAST\") \\\n",
    "                .load(\"dbfs:/tmp/broken.csv\")\n",
    "display(ratings_broken_Failfast.limit(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd5aa2fe-307a-4e45-855c-c3b39a7d1a64",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>imdb_title_id</th><th>weighted_average_vote</th><th>total_votes</th><th>mean_vote</th><th>median_vote</th></tr></thead><tbody><tr><td>tt0000009</td><td>5.9</td><td>154</td><td>5.9</td><td>6.0</td></tr><tr><td>tt0001892</td><td>5.8</td><td>188</td><td>6.0</td><td>6.0</td></tr><tr><td>tt0002101</td><td>5.2</td><td>446</td><td>5.3</td><td>5.0</td></tr><tr><td>tt0002199</td><td>5.7</td><td>484</td><td>5.8</td><td>6.0</td></tr><tr><td>tt0002461</td><td>5.5</td><td>225</td><td>5.4</td><td>6.0</td></tr><tr><td>tt0003167</td><td>5.8</td><td>187</td><td>6.1</td><td>6.0</td></tr><tr><td>tt0003471</td><td>6.0</td><td>552</td><td>6.0</td><td>6.0</td></tr><tr><td>tt0003772</td><td>6.0</td><td>929</td><td>6.7</td><td>7.0</td></tr><tr><td>tt0003973</td><td>5.8</td><td>202</td><td>6.0</td><td>6.0</td></tr><tr><td>tt0004099</td><td>5.2</td><td>415</td><td>5.2</td><td>5.0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "tt0000009",
         5.9,
         154,
         5.9,
         6.0
        ],
        [
         "tt0001892",
         5.8,
         188,
         6.0,
         6.0
        ],
        [
         "tt0002101",
         5.2,
         446,
         5.3,
         5.0
        ],
        [
         "tt0002199",
         5.7,
         484,
         5.8,
         6.0
        ],
        [
         "tt0002461",
         5.5,
         225,
         5.4,
         6.0
        ],
        [
         "tt0003167",
         5.8,
         187,
         6.1,
         6.0
        ],
        [
         "tt0003471",
         6.0,
         552,
         6.0,
         6.0
        ],
        [
         "tt0003772",
         6.0,
         929,
         6.7,
         7.0
        ],
        [
         "tt0003973",
         5.8,
         202,
         6.0,
         6.0
        ],
        [
         "tt0004099",
         5.2,
         415,
         5.2,
         5.0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "imdb_title_id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "weighted_average_vote",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "total_votes",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "mean_vote",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "median_vote",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ratings_broken_Dropmalformed = spark.read.format('csv') \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "        .schema(ratings_schema) \\\n",
    "            .option(\"mode\", \"DROPMALFORMED\") \\\n",
    "                .load(\"dbfs:/tmp/broken.csv\")\n",
    "display(ratings_broken_Dropmalformed.limit(10))\n",
    "\n",
    "# efekt jest taki ze zosta;y usuniete te wiersze gdzie wystepowal null w kolumnie weighted_average_vote\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3c0fa0a-0eba-46f7-80a5-fcb49579f2f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>imdb_title_id</th><th>weighted_average_vote</th><th>total_votes</th><th>mean_vote</th><th>median_vote</th></tr></thead><tbody><tr><td>tt0000009</td><td>5.9</td><td>154</td><td>5.9</td><td>6.0</td></tr><tr><td>tt0001892</td><td>5.8</td><td>188</td><td>6.0</td><td>6.0</td></tr><tr><td>tt0002101</td><td>5.2</td><td>446</td><td>5.3</td><td>5.0</td></tr><tr><td>tt0002199</td><td>5.7</td><td>484</td><td>5.8</td><td>6.0</td></tr><tr><td>tt0002461</td><td>5.5</td><td>225</td><td>5.4</td><td>6.0</td></tr><tr><td>tt0003167</td><td>5.8</td><td>187</td><td>6.1</td><td>6.0</td></tr><tr><td>tt0003471</td><td>6.0</td><td>552</td><td>6.0</td><td>6.0</td></tr><tr><td>tt0003772</td><td>6.0</td><td>929</td><td>6.7</td><td>7.0</td></tr><tr><td>tt0003973</td><td>5.8</td><td>202</td><td>6.0</td><td>6.0</td></tr><tr><td>tt0004099</td><td>5.2</td><td>415</td><td>5.2</td><td>5.0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "tt0000009",
         5.9,
         154,
         5.9,
         6.0
        ],
        [
         "tt0001892",
         5.8,
         188,
         6.0,
         6.0
        ],
        [
         "tt0002101",
         5.2,
         446,
         5.3,
         5.0
        ],
        [
         "tt0002199",
         5.7,
         484,
         5.8,
         6.0
        ],
        [
         "tt0002461",
         5.5,
         225,
         5.4,
         6.0
        ],
        [
         "tt0003167",
         5.8,
         187,
         6.1,
         6.0
        ],
        [
         "tt0003471",
         6.0,
         552,
         6.0,
         6.0
        ],
        [
         "tt0003772",
         6.0,
         929,
         6.7,
         7.0
        ],
        [
         "tt0003973",
         5.8,
         202,
         6.0,
         6.0
        ],
        [
         "tt0004099",
         5.2,
         415,
         5.2,
         5.0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "imdb_title_id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "weighted_average_vote",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "total_votes",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "mean_vote",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "median_vote",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Bad records\n",
    "ratings_broken_BadRecords = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "        .schema(ratings_schema) \\\n",
    "            .option(\"badRecordsPath\", \"/mnt/source/badrecords\") \\\n",
    "                .load(\"dbfs:/tmp/broken.csv\")\n",
    "display(ratings_broken_BadRecords.limit(10))\n",
    "\n",
    "# efekt jest taki ze zosta;y usuniete te wiersze gdzie wystepowal null w kolumnie weighted_average_vote\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c219ccb1-12c2-4d49-8c9f-bd8a78fffc16",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Zadanie 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8145b62a-0636-460e-a112-d80f75f43515",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>imdb_title_id</th><th>weighted_average_vote</th><th>total_votes</th><th>mean_vote</th><th>median_vote</th></tr></thead><tbody><tr><td>tt0317342</td><td>6.3</td><td>218</td><td>6.8</td><td>7.0</td></tr><tr><td>tt0317351</td><td>7.1</td><td>120</td><td>7.6</td><td>8.0</td></tr><tr><td>tt0317352</td><td>6.5</td><td>261</td><td>7.0</td><td>7.0</td></tr><tr><td>tt0317469</td><td>6.1</td><td>360</td><td>6.1</td><td>6.0</td></tr><tr><td>tt0317476</td><td>6.8</td><td>398</td><td>6.7</td><td>7.0</td></tr><tr><td>tt0317521</td><td>4.5</td><td>285</td><td>5.1</td><td>5.0</td></tr><tr><td>tt0317535</td><td>4.6</td><td>226</td><td>5.1</td><td>5.0</td></tr><tr><td>tt0317603</td><td>5.8</td><td>246</td><td>6.1</td><td>6.0</td></tr><tr><td>tt0317640</td><td>6.1</td><td>4587</td><td>6.6</td><td>7.0</td></tr><tr><td>tt0317648</td><td>6.7</td><td>76379</td><td>6.8</td><td>7.0</td></tr><tr><td>tt0317676</td><td>2.0</td><td>35615</td><td>2.3</td><td>1.0</td></tr><tr><td>tt0317680</td><td>5.6</td><td>166</td><td>6.1</td><td>6.0</td></tr><tr><td>tt0317705</td><td>8.0</td><td>642759</td><td>8.0</td><td>8.0</td></tr><tr><td>tt0317740</td><td>7.0</td><td>337492</td><td>7.1</td><td>7.0</td></tr><tr><td>tt0317743</td><td>7.1</td><td>2800</td><td>7.2</td><td>7.0</td></tr><tr><td>tt0317751</td><td>7.0</td><td>161</td><td>7.1</td><td>7.0</td></tr><tr><td>tt0317763</td><td>5.0</td><td>167</td><td>5.5</td><td>6.0</td></tr><tr><td>tt0317772</td><td>7.1</td><td>262</td><td>7.2</td><td>7.0</td></tr><tr><td>tt0317793</td><td>7.1</td><td>204</td><td>7.1</td><td>7.0</td></tr><tr><td>tt0317794</td><td>6.7</td><td>785</td><td>6.9</td><td>7.0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "tt0317342",
         6.3,
         218,
         6.8,
         7.0
        ],
        [
         "tt0317351",
         7.1,
         120,
         7.6,
         8.0
        ],
        [
         "tt0317352",
         6.5,
         261,
         7.0,
         7.0
        ],
        [
         "tt0317469",
         6.1,
         360,
         6.1,
         6.0
        ],
        [
         "tt0317476",
         6.8,
         398,
         6.7,
         7.0
        ],
        [
         "tt0317521",
         4.5,
         285,
         5.1,
         5.0
        ],
        [
         "tt0317535",
         4.6,
         226,
         5.1,
         5.0
        ],
        [
         "tt0317603",
         5.8,
         246,
         6.1,
         6.0
        ],
        [
         "tt0317640",
         6.1,
         4587,
         6.6,
         7.0
        ],
        [
         "tt0317648",
         6.7,
         76379,
         6.8,
         7.0
        ],
        [
         "tt0317676",
         2.0,
         35615,
         2.3,
         1.0
        ],
        [
         "tt0317680",
         5.6,
         166,
         6.1,
         6.0
        ],
        [
         "tt0317705",
         8.0,
         642759,
         8.0,
         8.0
        ],
        [
         "tt0317740",
         7.0,
         337492,
         7.1,
         7.0
        ],
        [
         "tt0317743",
         7.1,
         2800,
         7.2,
         7.0
        ],
        [
         "tt0317751",
         7.0,
         161,
         7.1,
         7.0
        ],
        [
         "tt0317763",
         5.0,
         167,
         5.5,
         6.0
        ],
        [
         "tt0317772",
         7.1,
         262,
         7.2,
         7.0
        ],
        [
         "tt0317793",
         7.1,
         204,
         7.1,
         7.0
        ],
        [
         "tt0317794",
         6.7,
         785,
         6.9,
         7.0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "imdb_title_id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "weighted_average_vote",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "total_votes",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "mean_vote",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "median_vote",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DataFrameWriter\n",
    "\n",
    "\n",
    "# Parquet\n",
    "schema.write.format(\"parquet\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "            .save(\"dbfs:/tmp/ratings_parquet\")\n",
    "\n",
    "DataParquet = spark.read.format(\"parquet\") \\\n",
    "    .schema(ratings_schema) \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "            .load(\"dbfs:/tmp/ratings_parquet\")\n",
    "display(DataParquet.limit(20))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03dfb9bd-854b-4857-bcf2-0ab37c195577",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>imdb_title_id</th><th>weighted_average_vote</th><th>total_votes</th><th>mean_vote</th><th>median_vote</th></tr></thead><tbody><tr><td>tt0000009</td><td>5.9</td><td>154</td><td>5.9</td><td>6.0</td></tr><tr><td>tt0000574</td><td>6.1</td><td>589</td><td>6.3</td><td>6.0</td></tr><tr><td>tt0001892</td><td>5.8</td><td>188</td><td>6.0</td><td>6.0</td></tr><tr><td>tt0002101</td><td>5.2</td><td>446</td><td>5.3</td><td>5.0</td></tr><tr><td>tt0002130</td><td>7.0</td><td>2237</td><td>6.9</td><td>7.0</td></tr><tr><td>tt0002199</td><td>5.7</td><td>484</td><td>5.8</td><td>6.0</td></tr><tr><td>tt0002423</td><td>6.8</td><td>753</td><td>6.8</td><td>7.0</td></tr><tr><td>tt0002445</td><td>6.2</td><td>273</td><td>6.2</td><td>6.0</td></tr><tr><td>tt0002452</td><td>6.7</td><td>198</td><td>7.1</td><td>7.0</td></tr><tr><td>tt0002461</td><td>5.5</td><td>225</td><td>5.4</td><td>6.0</td></tr><tr><td>tt0002646</td><td>6.6</td><td>331</td><td>6.6</td><td>7.0</td></tr><tr><td>tt0002844</td><td>7.0</td><td>1944</td><td>6.6</td><td>7.0</td></tr><tr><td>tt0003014</td><td>7.1</td><td>948</td><td>7.2</td><td>7.0</td></tr><tr><td>tt0003037</td><td>7.0</td><td>1349</td><td>6.5</td><td>7.0</td></tr><tr><td>tt0003102</td><td>6.2</td><td>100</td><td>6.3</td><td>6.0</td></tr><tr><td>tt0003131</td><td>6.5</td><td>124</td><td>6.7</td><td>7.0</td></tr><tr><td>tt0003165</td><td>7.0</td><td>1050</td><td>6.6</td><td>7.0</td></tr><tr><td>tt0003167</td><td>5.8</td><td>187</td><td>6.1</td><td>6.0</td></tr><tr><td>tt0003419</td><td>6.5</td><td>1768</td><td>6.5</td><td>7.0</td></tr><tr><td>tt0003471</td><td>6.0</td><td>552</td><td>6.0</td><td>6.0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "tt0000009",
         5.9,
         154,
         5.9,
         6.0
        ],
        [
         "tt0000574",
         6.1,
         589,
         6.3,
         6.0
        ],
        [
         "tt0001892",
         5.8,
         188,
         6.0,
         6.0
        ],
        [
         "tt0002101",
         5.2,
         446,
         5.3,
         5.0
        ],
        [
         "tt0002130",
         7.0,
         2237,
         6.9,
         7.0
        ],
        [
         "tt0002199",
         5.7,
         484,
         5.8,
         6.0
        ],
        [
         "tt0002423",
         6.8,
         753,
         6.8,
         7.0
        ],
        [
         "tt0002445",
         6.2,
         273,
         6.2,
         6.0
        ],
        [
         "tt0002452",
         6.7,
         198,
         7.1,
         7.0
        ],
        [
         "tt0002461",
         5.5,
         225,
         5.4,
         6.0
        ],
        [
         "tt0002646",
         6.6,
         331,
         6.6,
         7.0
        ],
        [
         "tt0002844",
         7.0,
         1944,
         6.6,
         7.0
        ],
        [
         "tt0003014",
         7.1,
         948,
         7.2,
         7.0
        ],
        [
         "tt0003037",
         7.0,
         1349,
         6.5,
         7.0
        ],
        [
         "tt0003102",
         6.2,
         100,
         6.3,
         6.0
        ],
        [
         "tt0003131",
         6.5,
         124,
         6.7,
         7.0
        ],
        [
         "tt0003165",
         7.0,
         1050,
         6.6,
         7.0
        ],
        [
         "tt0003167",
         5.8,
         187,
         6.1,
         6.0
        ],
        [
         "tt0003419",
         6.5,
         1768,
         6.5,
         7.0
        ],
        [
         "tt0003471",
         6.0,
         552,
         6.0,
         6.0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "imdb_title_id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "weighted_average_vote",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "total_votes",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "mean_vote",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "median_vote",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Json\n",
    "\n",
    "schema.write.format(\"json\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "            .save(\"dbfs:/tmp/ratings_json\")\n",
    "\n",
    "DataJson = spark.read.format(\"json\") \\\n",
    "    .schema(ratings_schema) \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "            .load(\"dbfs:/tmp/ratings_json\")\n",
    "display(DataJson.limit(20))\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Lab2_cz2",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
